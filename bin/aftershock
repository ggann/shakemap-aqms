#! /usr/bin/env python

# System imports
import os
import os.path
import sys
import logging
from logging.handlers import TimedRotatingFileHandler
import socket
import argparse
from datetime import datetime

# Third-party imports
import daemon
import lockfile
import sqlite3

# Local imports
from shakemap.utils.config import get_config_paths
from shakelib.rupture import constants  # added by GG
import shakemap.utils.queue as queue
from shakemap_aqms.util import (get_aqms_config,
                                get_eqinfo)


class aftershockDB(object):
    """Class to build or retrieve a database for aftershock suppression. 
    The db file can be removed if the operator wants a fresh start.
    """
    def __init__(self, ipath):

        exclude_table = """ CREATE TABLE excludes (
                                eid INTEGER PRIMARY KEY AUTOINCREMENT,
                                eruleid INTEGER NOT NULL,
                                ev1y REAL,
                                ev1x REAL,
                                ev2y REAL,
                                ev2x REAL,
                                ev3y REAL,
                                ev3x REAL,
                                emaglimit REAL DEFAULT 0.000,
                                eplacename TEXT,
                                added DATE
                            ); """

        self.db_file = os.path.join(ipath, 'data', 'aftershock_excludes.db')
        db_exists = os.path.isfile(self.db_file)
        self._connection = sqlite3.connect(self.db_file, timeout=15)
        if self._connection is None:
            raise RuntimeError('Could not connect to %s' % self.db_file)
        self._connection.isolation_level = 'EXCLUSIVE'
        self._cursor = self._connection.cursor()
        self._cursor.execute('PRAGMA foreign_keys = ON')
        self._cursor.execute('PRAGMA journal_mode = WAL')
        if not db_exists:
            self._cursor.execute(exclude_table)



    def __del__(self):
        """Destructor.

        """
        if hasattr(self, '_connection') and self._connection is not None:
            self._disconnect()

    def _disconnect(self):
        self.commit()
        self._cursor.close()
        self._connection.close()
        self._connection = None
        self._cursor = None

    def commit(self):
        """Commit any operations to the database.
        """
        self._connection.commit()


    def insertAftershockZone(self, valuesDict):
        """Construct and insert a new aftershock exclusion zone into the database
        """
    """
q{INSERT INTO excludes (eruleid,ev1y,ev1x,ev2y,ev2x,ev3y,ev3x,emaglimit,eplacename,added) VALUES ('%d','%4.2f','%4.2f','%4.2f','%4.2f','%4.2f','%4.2f','%3.1f','%s','%s')},
          $eruleid, $triangles[$i], $triangles[ $i + 1 ], $triangles[ $i + 2 ],
          $triangles[ $i + 3 ], $triangles[ $i + 4 ], $triangles[ $i + 5 ],
          $emaglimit, $eplacename, $gmdate;


    --source of the values--
    eid INTEGER PRIMARY KEY AUTOINCREMENT (keeps the triangle records unique)
    eruleid->comes from aftershock_define, determines if need to create or update zone
   
    (ev1y, ev1x, ev2y, ev2x, ev3y, ev3x)->three points of a triangle representing the region
    There are between 4-8 triangles constructed for a single aftershock exclusion zone
    After a single triangle is inserted a "dateline" check is run by the code.  
    If said triangle crosses this dateline, values are modified and yet another triangle is inserted into DB. 
    Values needed to construct the triangles:  mag, lon, lat

    emaglimit->magnitude limit for determining exclusion threshold, usually set to (mag - 2) LET'S SET THIS THRESHOLD IN CONFIG
    eplacename->is the event ID with net i.e. ci84838493
    added->the datetime added    
"""
#    my (
#        $eruleid,    $nsec,      $nmin,        $nhour,
#        $nmday,      $nmon,      $nyear,       $nwday,
#        $nyday,      $nisdst,    $TIME,        $gmdate,
#        $olderuleid, $emaglimit, $excludename, $exclude
#    );
#    my (
#        $len,      $eastlon,  $westlon,  $midlon,
#        $eastlon2, $westlon2, $northlat, $southlat
#    );
#    my ( $datelineflag, $eplacename );

    $TIME       = time;
    $eplacename = uc($net) . $eventid;

    $sql = 'SELECT max(eruleid) from excludes';
    $sth = $dbh->prepare("$sql");
    $sth->execute
      or die "Unable to execute query: $dbh->errstr\n";
    while ( @row = $sth->fetchrow_array ) {
        $eruleid = $row[0] + 1;
        print {$LOG} "Assigning eruleid $eruleid to event $net $eventid\n";
    }
    $sth->finish;
    ( $nsec, $nmin, $nhour, $nmday, $nmon, $nyear, $nwday, $nyday, $nisdst ) =
      gmtime $TIME;
    $nmon++;
    $nyear = $nyear + 1900;
    $gmdate = sprintf '%04d-%02d-%02d', $nyear, $nmon, $nmday, $nhour, $nmin,
      $nsec;

###    $len = 10**( $mag - 5 ) + 5;
#
# Got this formula from Morgan Page - sms 30apr2010
# The old formula that I got from Lucy was making the zone too
# big for large events. If we had another Sumatra event, the
# aftershock zone would cover the entire Earth, and that is just
# too broad a brush for this application. So Morgan dug out a
# paper from her desk and found the following formula:
# Wells and Coppersmith (1994) Surface rupture length (all slip types)
# to magnitude
    $len = 10**(0.69*$mag - 3.22);
#
# Multiply by 2 for two rupture lengths
    $len = $len * 2;

    print {$LOG} "Length is $len km\n";

    my $pi          = 3.1415927;
    my $deg2rad     = 0.17453293e-1;
    my $rad2deg     = 57.295779;
    my $earthradius = 6371;            # earthradius in km
    my $sqrt3       = 1.732050807;

    $londiff = 2 * $pi * ( $len / ( 2 * $pi * $earthradius ) ) * $rad2deg;
    $eastlon = $lon + $londiff;
    $westlon = $lon - $londiff;

    $midlon   = $londiff / 2;
    $eastlon2 = $lon + $midlon;
    $westlon2 = $lon - $midlon;

    $latdiff =
      2 *
      $pi *
      ( ( $sqrt3 * $len / 2 ) / ( 2 * $pi * $earthradius ) ) *
      $rad2deg;
    $northlat = $lat + $latdiff;
    $southlat = $lat - $latdiff;

    print {$LOG}
"Zone runs from $eastlon to $westlon\nLat goes from $northlat to $southlat\n";

    print {$LOG} "Proposed points are:\n";
    print {$LOG} "  $lat/$westlon\n";
    print {$LOG} "  $northlat/$westlon2\n";
    print {$LOG} "  $northlat/$eastlon2\n";
    print {$LOG} "  $lat/$eastlon\n";
    print {$LOG} "  $southlat/$eastlon2\n";
    print {$LOG} "  $southlat/$westlon2\n";

    print {$LOG} "\nTriangles are:\n";
    printf {$LOG} "%3.3f/%3.3f, %3.3f/%3.3f, %3.3f/%3.3f\n", $lat, $westlon,
      $northlat, $westlon2, $northlat, $eastlon2;
    printf {$LOG} "%3.3f/%3.3f, %3.3f/%3.3f, %3.3f/%3.3f\n", $lat, $westlon,
      $northlat, $eastlon2, $southlat, $westlon2;
    printf {$LOG} "%3.3f/%3.3f, %3.3f/%3.3f, %3.3f/%3.3f\n", $northlat,
      $eastlon2, $lat, $eastlon, $southlat, $westlon2;
    printf {$LOG} "%3.3f/%3.3f, %3.3f/%3.3f, %3.3f/%3.3f\n", $lat, $eastlon,
      $southlat, $eastlon2, $southlat, $westlon2;

    my @triangles = (
        $lat,      $westlon,  $northlat, $westlon2, $northlat, $eastlon2,
        $lat,      $westlon,  $northlat, $eastlon2, $southlat, $westlon2,
        $northlat, $eastlon2, $lat,      $eastlon,  $southlat, $westlon2,
        $lat,      $eastlon,  $southlat, $eastlon2, $southlat, $westlon2
    );

    $emaglimit = $mag - 2;

    print {$LOG} "\nMagnitude level is $emaglimit\n";

    #      $sql = "DELETE FROM excludes where eruleid=$eruleid";
    #      $sth = $dbh->prepare("$sql");
    #      $sth->execute or
    #   die "Unable to execute query: $dbh->errstr\n";
    #      $sth->finish;

    for ( $i = 0 ; $i <= 18 ; $i = $i + 6 ) {
        $datelineflag = 0;
        $sql =
          sprintf
q{INSERT INTO excludes (eruleid,ev1y,ev1x,ev2y,ev2x,ev3y,ev3x,emaglimit,eplacename,added) VALUES ('%d','%4.2f','%4.2f','%4.2f','%4.2f','%4.2f','%4.2f','%3.1f','%s','%s')},
          $eruleid, $triangles[$i], $triangles[ $i + 1 ], $triangles[ $i + 2 ],
          $triangles[ $i + 3 ], $triangles[ $i + 4 ], $triangles[ $i + 5 ],
          $emaglimit, $eplacename, $gmdate;
        print {$LOG} "SQL is $sql\n";
        $sth = $dbh->prepare("$sql");
        $sth->execute
          or die "Unable to execute query: $dbh->errstr\n";
        $sth->finish;

        if (   ( $triangles[1] > 180 )
            || ( $triangles[3] > 180 )
            || ( $triangles[5] > 180 ) )
        {
            print {$LOG} "This triangle crosses the Date Line at 180\n";
            $datelineflag = 1;
        }
        if (   ( $triangles[1] < -180 )
            || ( $triangles[3] < -180 )
            || ( $triangles[5] < -180 ) )
        {
            print {$LOG} "This triangle crosses the Date Line at -180\n";
            $datelineflag = -1;
        }
        if ( $datelineflag != 0 ) {

            $triangles[1] = $triangles[1] - $datelineflag * 360;
            $triangles[3] = $triangles[3] - $datelineflag * 360;
            $triangles[5] = $triangles[5] - $datelineflag * 360;
            $sql =
              sprintf
q{INSERT INTO excludes (eruleid,ev1y,ev1x,ev2y,ev2x,ev3y,ev3x,emaglimit,eplacename,added) VALUES ('%d','%4.2f','%4.2f','%4.2f','%4.2f','%4.2f','%4.2f','%3.1f','%s','%s')},
              $eruleid, $triangles[$i], $triangles[ $i + 1 ],
              $triangles[ $i + 2 ], $triangles[ $i + 3 ], $triangles[ $i + 4 ],
              $triangles[ $i + 5 ], $emaglimit, $eplacename, $gmdate;
            print {$LOG} "SQL is $sql\n";
            $sth = $dbh->prepare("$sql");
            $sth->execute
              or die "Unable to execute query: $dbh->errstr\n";
            $sth->finish;
        }
    }
    return 0;
}



#    def getQueuedEvents(self):
#        query = 'SELECT eventid, command, mag FROM queued ORDER BY mag DESC'
#        self._cursor.execute(query)
#        erows = self._cursor.fetchall()
#        return [(x[0], json.loads(x[1])) for x in erows]

#    def queueEvent(self, eventid, command, mag):
#        query = 'REPLACE INTO queued (eventid, command, mag) VALUES (?, ?, ?)'
#        self._cursor.execute(query, (eventid, json.dumps(command), mag))
#        self.commit()

#    def dequeueEvent(self, eventid):
#        query = 'DELETE FROM queued WHERE eventid = ?'
#        self._cursor.execute(query, (eventid,))
#        self.commit()

#    def getRunningEvents(self):
#        query = 'SELECT eventid, command FROM running'
#        self._cursor.execute(query)
#        erows = self._cursor.fetchall()
#        return [(x[0], json.loads(x[1])) for x in erows]

#    def insertRunningEvent(self, eventid, command):
#        query = 'INSERT INTO running (eventid, command) VALUES (?, ?)'
#        self._cursor.execute(query, (eventid, json.dumps(command)))
#        self.commit()

#    def deleteRunningEvent(self, eventid):
#        query = 'DELETE FROM running WHERE eventid = ?'
#        self._cursor.execute(query, (eventid,))
#        self.commit()

def get_logger(logpath, attached):
    """Set up a logger for this process.

    Args:
        logpath (str): Path to the directory into which to put the logfile.

    Returns:
        logging.logger: An instance of a logger.
    """
    logger = logging.getLogger('aqms_queue_logger')
    logger.setLevel(logging.INFO)
    if not attached:
        logfile = os.path.join(logpath, 'aqms_queue.log')
        handler = TimedRotatingFileHandler(logfile,
                                           when='midnight',
                                           backupCount=60)
        formatter = logging.Formatter(
                fmt='%(asctime)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.propagate = False
    else:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
                fmt='%(asctime)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger


class Dummycontext(object):
    def __enter__(self): return self

    def __exit__(*x): pass


def get_context(context, attached):
    if attached:
        return Dummycontext()
    else:
        return context


def get_parser():
    """Make an argument parser.

    Returns:
        ArgumentParser: an argparse argument parser.
    """
    description = """
    Run a daemon process to accept alarm and cancel mmessages
    and send the resulting data to sm_queue.
    """
    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('-a', '--attached', action='store_true',
                        help='Inhibit daemonization and remain attached '
                             'to the terminal (for testing).')
    return parser




def main(pargs):

    install_path, data_path = get_config_paths()

    aqms_conf = get_aqms_config()
    queue_conf = get_aqms_config('aqms_queue')

    sm_queue_config = queue.get_config(install_path)

    if 'localhost' not in queue_conf['servers']:
        queue_conf['servers'].append('localhost')
    #
    # Turn this process into a daemon
    #
    logpath = os.path.join(install_path, 'logs')
    if not os.path.isdir(logpath):
        os.makedirs(logpath)
    pidfile = os.path.join(logpath, 'aqms_queue.pid')
    context = daemon.DaemonContext(
            working_directory=data_path,
            pidfile=lockfile.FileLock(pidfile))

    with get_context(context, pargs.attached):
        logger = get_logger(logpath, pargs.attached)
        #
        # Create/retrieve the database for aftershock suppression
        #
        if 'aftershock' in queue_conf:  # aftershock flag is set, proceed 
            self.aftershockDB = aftershockDB(install_path)
        #
        # Create the socket
        #
        qsocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        qsocket.bind(('', queue_conf['port']))
        # Set a timeout so that we can occasionally look for other
        # things to do
        qsocket.settimeout(30)
        qsocket.listen(5)

        logger.info('aqms_queue initiated')

        while True:
            #
            # Now wait for a connection
            #
            try:
                (clientsocket, address) = qsocket.accept()
            except socket.timeout:
                #
                # Normal timeout; do routine tasks and then go
                # back to waiting for a connection
                #
                continue
            #
            # Got a connection
            #
            hostname, _, _ = socket.gethostbyaddr(address[0])
#            hostname = socket.getfqdn(hostname)
            logger.info('Got connection from %s at port %s' %
                        (hostname, address[1]))

            if hostname not in queue_conf['servers']:
                logger.warning('Connection from %s refused: not in valid '
                               'servers list' % hostname)
                clientsocket.close()
                continue

            #
            # The accept() should guarantee that there's something
            # to read, but something could go wrong...
            #
            try:
                clientsocket.settimeout(10)
                data = clientsocket.recv(queue.MAX_SIZE)
            except socket.timeout:
                logger.warning('Did not get data from connection, continuing')
                clientsocket.close()
                continue
            else:
                clientsocket.close()
            #
            # Decode the data and do something
            #
            action, eventid, update = data.decode('utf-8').split(maxsplit=2)

            if action == 'shake_alarm':
                logger.info('Got shake_alarm for event %s' % eventid)
                event = get_eqinfo(eventid, aqms_conf, logger)

                if event is None:
                    logger.warning("Couldn't find event %s in database" %
                                   eventid)
                    continue
                try:
                    # Shakemap code keeps value as datetime, need string for JSON parsing by queue
                    dt = event['time']
                    event['time'] = dt.strftime(constants.TIMEFMT)
                    queue.send_queue('origin', event, sm_queue_config['port'])
                except Exception as e:
                    logger.error("Couldn't send event %s to sm_queue" %
                                 eventid)
                    logger.error(e)
                else:
                    logger.info('Sent event %s to sm_queue' % eventid)
            elif action == 'shake_cancel':
                logger.info('Got shake_cancel for event %s' % eventid)
                try:
                    queue.send_queue('cancel', {'id': eventid},
                                     sm_queue_config['port'])
                except Exception:
                    logger.error("Couldn't send cancel event %s to sm_queue" %
                                 eventid)
                else:
                    logger.info('Sent cancel event %s to sm_queue' % eventid)
            else:
                logger.warning('Unknown action: %s; ignoring' % action)


if __name__ == '__main__':

    parser = get_parser()
    pargs = parser.parse_args()

    main(pargs)
